# Transfer Learning Demo

基于日本餐厅客流量数据的迁移学习演示项目。

## 项目概述

本项目旨在解决HPG平台因缺乏真实客流标签而难以准确预测的问题。通过从拥有丰富真实客流数据的AIR平台向HPG平台迁移知识，提升目标平台的预测性能。

### 核心问题
- HPG平台仅有预订数据，缺少真实的客流量标签，难以直接训练高质量预测模型
- AIR平台具有完整的历史客流记录，可用于构建强特征表示和预训练模型
- 如何有效将在AIR平台学到的数据分布和特征模式迁移到HPG平台

## 项目结构

```
.
├── data/                   # 数据目录
│   ├── inputs/             # 原始输入数据
│   ├── intermediates/      # 中间处理数据
│   └── outputs/            # 最终输出数据
├── lgbm_weights/           # 模型权重保存目录
├── src/                    # 源代码目录
│   ├── data_transformation/# 数据处理模块
│   └── model/              # 机器学习模型模块
├── archive/                # 归档的历史尝试文件
├── RUN ME.ipynb           # 快速开始的Jupyter Notebook
└── demo_super_ensemble.py # 超级集成迁移学习演示脚本
```

## 技术栈

- Python 3.8+
- Polars: 高效数据处理
- LightGBM: 梯度提升框架
- Scikit-learn: 机器学习工具
- NumPy: 数值计算

## 快速开始

1. 安装依赖:
```bash
pip install -r requirements.txt
```

2. 运行演示:
```bash
python demo_super_ensemble.py
```

或者运行 Jupyter Notebook:
```bash
jupyter notebook "RUN ME.ipynb"
```

## 迁移学习方法

### 超级集成迁移学习 (推荐)

这是我们实现的最佳单模型迁移学习方法，结合了以下技术：

1. **智能样本筛选**
   - 使用聚类方法识别源域中与目标域最相关的样本
   - 仅选择最相关的样本参与训练，提高效率

2. **自适应特征对齐**
   - 分析源域和目标域特征的相关性
   - 只对相关性高的特征进行对齐处理

3. **两阶段训练策略**
   - 第一阶段：较高学习率快速收敛
   - 第二阶段：较低学习率精细调优

该方法在单个模型中集成了多种迁移学习技术，取得了最佳的性能表现。

## 性能表现

在HPG测试集上：
- 基线模型 (仅HPG数据): ~0.5664 RMSLE
- 超级集成迁移学习: ~0.5498 RMSLE
- 性能提升: ~2.92%

通过有效地利用源域(AIR)的知识，我们在目标域(HPG)上获得了显著的性能提升。

## 各种尝试总结

在项目开发过程中，我们尝试了多种迁移学习方法和技术，以下是各种尝试的总结：

### 成功的方法

#### 1. 超级集成迁移学习 (Super Ensemble Transfer Learning)
- **RMSLE**: 0.5498 (最佳结果)
- **描述**: 结合了智能样本筛选、自适应特征对齐和两阶段训练策略的单模型方法
- **优点**: 
  - 简洁而有效的方法组合
  - 充分利用了源域知识
  - 通过合理的参数设置获得最佳性能
- **适用场景**: 当只需要一个高性能单模型时的首选方法

#### 2. 微调 (Fine-tuning)
- **RMSLE**: ~0.5643
- **描述**: 在源域预训练模型基础上，在目标域数据上进行微调
- **优点**: 简单直接，易于理解和实现
- **缺点**: 性能提升有限

#### 3. CORAL 特征对齐
- **RMSLE**: 取决于具体实现，通常略好于微调
- **描述**: 通过协方差矩阵对齐源域和目标域的特征分布
- **优点**: 理论基础扎实，数学形式简洁
- **缺点**: 对所有特征同等对待，可能对不相关的特征产生负面影响

### 效果一般的方法

#### 1. 加权域适应 (Weighted Domain Adaptation)
- **RMSLE**: ~0.5673
- **描述**: 结合源域和目标域数据，给它们分配不同权重进行训练
- **分析**: 效果不如单独使用目标域数据训练，可能是因为源域和目标域之间存在较大的分布差异

#### 2. 伪标签迁移 (Pseudo-labeling Transfer)
- **RMSLE**: ~0.5638
- **描述**: 使用源域训练的模型为目标域数据生成伪标签，扩充训练数据
- **分析**: 略有改善，但提升有限，可能是因为伪标签的质量不够高

#### 3. 对抗域适应 (Adversarial Domain Adaptation)
- **RMSLE**: ~0.5632
- **描述**: 基于源模型的特征重要性调整目标域数据特征
- **分析**: 略有改善，但提升有限，实现复杂度较高

### 不成功的方法

#### 1. 改进的超级集成方法 (Improved Super Ensemble)
- **RMSLE**: 0.5515 (略逊于原始方法)
- **描述**: 尝试通过更复杂的特征重要性分析来指导样本筛选和特征对齐
- **分析**: 过度工程化，复杂的方法并不总是更好。额外的复杂性引入了噪声，反而降低了性能

#### 2. 精炼的超级集成方法 (Refined Super Ensemble)
- **RMSLE**: 0.6144 (显著下降)
- **描述**: 使用特征重要性指导的样本筛选和特征对齐
- **分析**: 复杂的特征分析反而损害了性能，说明简单的启发式方法有时更有效

#### 3. 保守微调方法 (Conservative Fine-tuning)
- **RMSLE**: 0.7839 (显著下降)
- **描述**: 使用极低学习率进行微调，试图最小化对源模型的更改
- **分析**: 学习率过低导致模型无法有效适应目标域，说明需要适当的"遗忘"才能更好地学习

#### 4. 对抗性域自适应样本筛选 + MMD损失约束
- **RMSLE**: 0.5564
- **描述**: 使用域判别器指导的动态样本选择和最大均值差异损失约束
- **分析**: 虽然理论上很有吸引力，但实际效果不如原始方法。域判别器准确率高达90.16%，说明两个域之间确实存在较大差异，但筛选出的样本可能仍然包含了噪声

#### 5. 参数正则化微调
- **RMSLE**: 0.5644
- **描述**: 通过参数正则化平衡源域知识保留与目标域适应
- **分析**: 效果略好于基线，但不如原始超级集成方法。正则化参数可能需要更精细的调整

#### 6. 迭代式伪标签优化
- **状态**: 实现过程中出现错误，未能得到结果
- **描述**: 通过置信度过滤 + 迭代更新提升伪标签质量
- **分析**: 置信度阈值可能过于严格，导致只有很少的样本被选中。LightGBM本身不直接支持不确定性估计，近似方法可能不够准确

### 经验教训

1. **简约有效性原则**: 过度复杂的改进策略可能导致性能下降。结构清晰、组合合理但不过度复杂的方案往往更稳定有效。

2. **方法组合优于单一技术**: 结合智能样本筛选、自适应特征对齐和分阶段训练的综合策略比任何单一技术更有效。

3. **参数调优的重要性**: 学习率、训练轮数等超参数对迁移学习效果有很大影响，需要仔细调优。

4. **验证集选择**: 验证集的大小和选择策略会显著影响模型的选择和最终性能。

5. **及时终止无效方向**: 当新方法在初步验证中表现不佳时，应迅速回退并尝试其他策略，避免过度投入。

6. **理论先进性 ≠ 实践有效性**: 即使方法在理论上具有优势（如对抗性筛选、MMD对齐），在特定任务和数据分布下，其复杂性可能引入额外风险，简单可靠的方法通常更具鲁棒性。

## 超参数调优实验

为了进一步提升模型性能，我们进行了系统的超参数调优实验。以下是不同设置下的性能对比：

| 方法 | 学习率阶段1 | 学习率阶段2 | 轮数阶段1 | 轮数阶段2 | RMSLE | 相比基线提升 |
|------|------------|------------|-----------|-----------|-------|-------------|
| 基线模型 | - | - | - | - | 0.5664 | - |
| 默认参数 | 0.01 | 0.002 | 500 | 3000 | 0.5498 | 2.92% |
| 调优版本1 | 0.007 | 0.001 | 800 | 2500 | 0.5515 | 2.63% |
| 调优版本2 | 0.005 | 0.001 | 1000 | 2000 | 0.5544 | 2.13% |
| 调优版本3 | 0.005 | 0.0005 | 800 | 2500 | 0.5569 | 1.68% |
| 调优版本4 | 0.003 | 0.001 | 1200 | 2000 | 0.5521 | 2.53% |

从实验结果可以看出，默认参数设置已经达到了较好的性能，进一步的调优虽然有一定改善空间，但提升幅度有限。这说明我们的默认参数选择是比较合理的。

在超参数调优过程中，我们发现：
1. 过低的学习率（如0.0005）会导致模型收敛缓慢，性能反而下降
2. 适度增加训练轮数有助于提升性能，但过多的轮数可能导致过拟合
3. 两阶段训练策略中，第一阶段较高的学习率有助于快速收敛，第二阶段较低的学习率有助于精细调优

## 总结

通过系统的实验和调优，我们验证了迁移学习在餐厅客流量预测任务中的有效性。超级集成迁移学习方法在不依赖复杂调参的情况下达到了最佳性能，证明了方法设计的重要性高于单纯的参数调优。

# Recruit餐厅访客预测项目

## 1. 项目概述

### 1.1 项目背景

本项目基于日本餐厅数据，利用迁移学习技术预测餐厅客流量。数据来源于Recruit Holdings公司旗下的两个平台：

- **Hot Pepper Gourmet (HPG)**: 类似于Yelp的餐厅点评服务，用户可以搜索餐厅并在线预订
- **AirREGI / Restaurant Board (AIR)**: 类似于Square的餐厅预订控制系统和收银系统

该项目旨在使用预订、访问和其他信息来预测未来特定日期的餐厅访客总数，这有助于餐厅更有效地采购食材和安排员工，提高运营效率。

### 11.2 核心预测问题

基于餐厅的历史访客记录、预订数据、日期特征（节假日/周末）、店铺属性（类型/区域）等信息，预测AIR系列餐厅未来的日访客数量，属于时间序列回归任务。

### 1.3 评估指标

提交结果使用均方根对数误差(RMSLE)进行评估：

$$\text{RMSLE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(\log(p_i + 1) - \log(a_i + 1))^2}$$

其中：
- n 是总观察数
- p_i 是对访客的预测
- a_i 是实际访客数
- log(x) 是 x 的自然对数

## 2. 数据集描述

### 2.1 数据集构成

这是一个来自两个系统的关联数据集。每个文件都以来源前缀（air_ 或 hpg_）标明其来源。每个餐厅都有唯一的air_store_id和hpg_store_id。需要注意的是，并非所有餐厅都被两个系统覆盖，而且提供给你的数据超出了你必须预测的餐厅范围。为了防止餐厅去标识化，纬度和经度并不完全精确。

### 2.2 文件详细说明

#### air_reserve.csv
此文件包含在AIR系统中进行的预订。

- air_store_id - AIR系统中的餐厅ID
- visit_datetime - 预订时间
- reserve_datetime - 创建预订的时间
- reserve_visitors - 该预订的访客数量

#### hpg_reserve.csv
此文件包含在HPG系统中进行的预订。

- hpg_store_id - HPG系统中的餐厅ID
- visit_datetime - 预订时间
- reserve_datetime - 创建预订的时间
- reserve_visitors - 该预订的访客数量

#### air_store_info.csv
此文件包含选定AIR餐厅的信息。

- air_store_id
- air_genre_name
- air_area_name
- latitude
- longitude
> 注意：纬度和经度是该餐厅所属区域的纬度和经度

#### hpg_store_info.csv
此文件包含选定HPG餐厅的信息。

- hpg_store_id
- hpg_genre_name
- hpg_area_name
- latitude
- longitude
> 注意：纬度和经度是该餐厅所属区域的纬度和经度

#### store_id_relation.csv
此文件允许你连接同时拥有AIR和HPG系统的选定餐厅。

- hpg_store_id
- air_store_id

#### air_visit_data.csv
此文件包含AIR餐厅的历史访问数据。

- air_store_id
- visit_date - 日期
- visitors - 该日期餐厅的访客数量

#### sample_submission.csv
此文件显示了正确格式的提交，包括必须预测的日期。

- id - ID由air_store_id和visit_date用下划线连接而成
- visitors - 预测的商店和日期组合的访客数量

#### date_info.csv
此文件提供了数据集中日历日期的基本信息。

- calendar_date
- day_of_week
- holiday_flg - 该日在日本是否为假日

## 3. 项目架构与实施步骤

### 3.1 项目结构

```
.
├── data/
│   ├── inputs/              # 原始数据目录
│   ├── intermediates/       # 中间处理结果目录
│   └── outputs/             # 最终输出数据目录
├── src/
│   ├── data_transformation/ # 数据转换模块
│   └── model/               # 模型训练模块
├── lgbm_weights/            # LightGBM模型权重文件
├── RUN ME.ipynb             # 主执行脚本
├── solution.py              # 原始解决方案（已移至archive目录）
├── requirements.txt         # 项目依赖
└── README.md               # 项目说明文档
```

### 3.2 数据处理流程

#### 第一步：数据加载与预处理

通过 `src.data_transformation.load_inputs` 加载所有原始数据文件，包括AIR和HPG的预订数据、店铺信息、访问数据等。

#### 第二步：数据合并

通过 `src.data_transformation.merge_reservation` 将AIR和HPG的预订数据合并，形成统一的预订数据表。

#### 第三步：特征工程

通过 `src.data_transformation.add_features_pipeline` 执行完整的特征工程流程，包括：
- 日期特征提取（星期几、是否节假日等）
- 店铺属性特征（类型、区域等）
- 预订相关统计特征
- 历史访问统计特征（多种时间窗口）

#### 第四步：数据集划分

根据店铺是否在两个平台都有数据，将数据划分为两组：
- AIR-only数据：仅在AIR平台有数据的店铺
- HPG-AIR关联数据：在两个平台都有数据的店铺

#### 第五步：生成标准化输出

生成四个标准化的数据集文件（Parquet格式）：
1. **air_train.parquet**: AIR-only训练集
2. **air_test.parquet**: AIR-only测试集
3. **hpg_train.parquet**: HPG-AIR关联训练集
4. **hpg_test.parquet**: HPG-AIR关联测试集

## 4. 模型训练

### 4.1 模型架构

项目使用LightGBM作为基础模型，通过以下模块进行训练：

- `src.model.prepare_lgbm_dataset_with_weights`: 数据预处理，包含时间加权机制
- `src.model.train_or_load_lgbm`: 模型训练或加载
- `src.model.evaluate_model`: 模型评估

### 4.2 训练策略

1. **时间加权**: 使用day_gap作为权重依据，距离预测日期越近的样本权重越高
2. **早停机制**: 使用验证集进行早停，防止过拟合
3. **模型持久化**: 训练好的模型保存在lgbm_weights目录中

### 4.3 运行方法

在项目根目录下执行RUN ME.ipynb notebook，程序将自动完成以下步骤：
1. 数据加载与预处理
2. 特征工程
3. 模型训练
4. 模型评估

## 5. 技术实现细节

### 5.1 环境依赖

项目主要依赖以下Python库：
- polars: 高性能数据处理库
- numpy: 数值计算库
- scikit-learn: 机器学习库
- lightgbm: 梯度提升框架
- pandas: 数据分析库

### 5.2 核心代码组件

#### 数据转换模块 (src/data_transformation)
包含完整的数据处理流水线：
- load_data.py: 数据加载
- merge_reservation.py: 预订数据合并
- add_features目录: 特征工程实现

#### 模型模块 (src/model)
包含模型训练相关功能：
- baseline.py: 模型训练基础功能

## 6. 总结

本项目展示了如何使用迁移学习技术解决餐厅访客预测问题。通过精心设计的特征工程和时间加权训练策略，提升了模型在目标领域的预测性能。
